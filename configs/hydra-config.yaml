# Global configurations
project_name: Contrastive_Encoder
run_name: MoCoV3:${now:%Y-%m-%d_%H-%M-%S}
train_encoder: True
contrastive_encoder: True
train_diffusion: False
conditon: False
vis_diffusion: False
train_classifier: False
encoder_checkpoint_name: vae_phaseepoch=96_val_loss=0.0005596.ckpt
# diffusion_checkpoint_name: diffusion_condition_3MParams_epoch=181_val_loss=0.0757.ckpt
diffusion_checkpoint_name: diffusion_no_condition_2.3MParams_epoch=191_val_loss=0.0702.ckpt
mode: online
debug: False
log_model: True
seed: 42

# In your hydra config
hyperparams:
    # Training
    epochs: 100
    classifier_epochs: 10
    learning_rate: .0001
    batch_size: 256
    contrastive_batch_size: 2048 # make this high so we can use all negatives in batch without increase batch for diffusion model
    dropout: 0.25
    hidden_dim: 32
    feature_dim: 16
    num_classes: 11

# Paths
output_dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
data_dir: data/

# Encoder_Reconstruction:
#     _target_: models.latent_encoder_models.latent_reconstruction_encoder.LatentEncoderReconstrction
#     learning_rate: .0005
#     encoder:
#         _target_: models.latent_encoder_models.resnet_encoder.ResNet1D
#     decoder:
#         _target_: models.latent_encoder_models.decoder.Decoder1D

Encoder:
    _target_: models.latent_encoder_models.MoCoV3Encoder.MoCoV3Encoder
    learning_rate: .001
    encoder:
        _target_: models.latent_encoder_models.resnet_encoder.ResNet1D

Diffusion:
    _target_: models.diffusion.latent_diffusion.LatentDiffusion
    learning_rate: ${hyperparams.learning_rate}
    n_steps: 500
    linear_start: 0.0001 # starting noise value for beta schedule
    linear_end: 0.01 # ending value for the beta schedule
    weight_decay: 1e-2
    latent_scaling: 2.98697 # 2.93873 # False - set to false if we want to recalcualte
    unet:
        _target_: models.diffusion.unet_1d.UNet1DModel
        sample_size: 64
        in_channels: 32
        out_channels: 32
        down_block_types:
            ["DownResnetBlock1D", "AttnDownBlock1D", "AttnDownBlock1D"]
        up_block_types: ["AttnUpBlock1D", "AttnUpBlock1D", "UpResnetBlock1D"]
        mid_block_type: "UNetMidBlock1D"
        block_out_channels: [32, 64, 128]
        layers_per_block: 3
        condition: ${conditon}
        conditional: 11 # Class conditioning

Classifier:
    _target_: models.classifier.classifier.LatentClassifier
    learning_rate: 0.0001
    fine_tune_diffusion: False
    num_classes: ${hyperparams.num_classes}
    classifier_head:
        _target_: models.classifier.conv_classifier.Conv1DHead
        num_classes: ${hyperparams.num_classes}

dataset:
    iq: true #true
    batch_size: ${hyperparams.batch_size}
    contrastive_batch_size: ${hyperparams.contrastive_batch_size}
    num_workers: 8
    train_val_split: [0.8, 0.2]
    random_seed: ${seed}
